{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "from cslib import fetch_ts, engineer_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading ts data from files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>purchases</th>\n",
       "      <th>unique_invoices</th>\n",
       "      <th>unique_streams</th>\n",
       "      <th>total_views</th>\n",
       "      <th>year_month</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  purchases  unique_invoices  unique_streams  total_views  \\\n",
       "0  2017-11-01          0                0               0            0   \n",
       "1  2017-11-02          0                0               0            0   \n",
       "2  2017-11-03          0                0               0            0   \n",
       "3  2017-11-04          0                0               0            0   \n",
       "4  2017-11-05          0                0               0            0   \n",
       "\n",
       "  year_month  revenue  \n",
       "0    2017-11      0.0  \n",
       "1    2017-11      0.0  \n",
       "2    2017-11      0.0  \n",
       "3    2017-11      0.0  \n",
       "4    2017-11      0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(\"data\",\"cs-train\")\n",
    "ts_all = fetch_ts(data_dir,clean=False)\n",
    "ts_all['all'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering and Train Test Split\n",
    "\n",
    "### Generate features using 7, 14, 28, 70-day time window wraping, the monthly sum of previous year, the average number of invoices and the total views in rencent 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,dates = engineer_features(ts_all['all'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Training and Perforamcne Comparision  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 16228.58\n",
      "mse = 455006311.93\n",
      "r2_score = 0.931\n",
      "explained_variance_score = 0.931\n",
      "best params = {'gb__criterion': 'mse', 'gb__n_estimators': 100}\n",
      "train time =  00:00:14\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid_gb = {\n",
    "    'gb__criterion': ['mse','mae'],\n",
    "    'gb__n_estimators': [10,15,20,25,50,100]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_gb = Pipeline(steps=[('scaler', StandardScaler()), ('gb', GradientBoostingRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_gb, param_grid=param_grid_gb, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "gb_mae =  mean_absolute_error(y_test, y_pred)\n",
    "gb_mse =  mean_squared_error(y_test, y_pred)\n",
    "gb_r2_score = r2_score(y_test, y_pred)\n",
    "gb_explained_variance_score = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"mae = {:.2f}\".format(gb_mae))\n",
    "print(\"mse = {:.2f}\".format(gb_mse))\n",
    "print(\"r2_score = {:.3f}\".format(gb_r2_score))\n",
    "print(\"best params =\", grid.best_params_)\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 11731.89\n",
      "mse = 279920599.40\n",
      "r2_score = 0.957\n",
      "explained_variance_score = 0.958\n",
      "best params = {'rf__criterion': 'mse', 'rf__n_estimators': 100}\n",
      "train time =  00:00:09\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'rf__criterion': ['mse','mae'],\n",
    "    'rf__n_estimators': [10,15,20,25,50,100]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe_rf = Pipeline(steps=[('scaler', StandardScaler()), ('rf', RandomForestRegressor())])\n",
    "\n",
    "grid = GridSearchCV(pipe_rf, param_grid=param_grid_rf, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "rf_mae =  mean_absolute_error(y_test, y_pred)\n",
    "rf_mse =  mean_squared_error(y_test, y_pred)\n",
    "rf_r2_score = r2_score(y_test, y_pred)\n",
    "rf_explained_variance_score = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"mae = {:.2f}\".format(rf_mae))\n",
    "print(\"mse = {:.2f}\".format(rf_mse))\n",
    "print(\"r2_score = {:.3f}\".format(rf_r2_score))\n",
    "print(\"best params =\", grid.best_params_)\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Multilayer Perceptron (MLP) Regressor\n",
    "A multilayer perceptron (MLP) is also known as a vanilla neural network because it is the core example of an architecture. The vanilla neural networks often only have a single hidden layer, but a MLP can have many more. The number of hidden layers and the size (number of nodes in each) are configurable parameters that you will need to keep in mind when building neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yee/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: RuntimeWarning: overflow encountered in square\n",
      "  array_means[:, np.newaxis]) ** 2,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 13951.61\n",
      "mse = 403412292.48\n",
      "r2_score = 0.939\n",
      "explained_variance_score = 0.939\n",
      "best params = {'nn__activation': 'relu', 'nn__hidden_layer_sizes': (10, 10), 'nn__solver': 'lbfgs'}\n",
      "train time =  00:01:19\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rs = 5\n",
    "param_grid = {\n",
    "    'nn__activation': ['relu'],\n",
    "    'nn__solver': ['lbfgs', 'sgd'],\n",
    "    'nn__hidden_layer_sizes': [(10,10), (50,50), (64, 64)]\n",
    "    }\n",
    "\n",
    "time_start = time.time()\n",
    "pipe  = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                            ('nn', MLPRegressor(alpha=1e-5, random_state=rs, max_iter=5000))])\n",
    "\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "nn_mae =  mean_absolute_error(y_test, y_pred)\n",
    "nn_mse =  mean_squared_error(y_test, y_pred)\n",
    "nn_r2_score = r2_score(y_test, y_pred)\n",
    "nn_explained_variance_score = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"mae = {:.2f}\".format(nn_mae))\n",
    "print(\"mse = {:.2f}\".format(nn_mse))\n",
    "print(\"r2_score = {:.3f}\".format(nn_r2_score))\n",
    "print(\"best params =\", grid.best_params_)\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"--------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Extreme Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae = 10986.26\n",
      "mse = 291398062.93\n",
      "r2_score = 0.956\n",
      "best params = {'xgb__tree_method': 'approx', 'xgb__objective': 'reg:squarederror', 'xgb__n_estimators': 650, 'xgb__min_child_weight': 3, 'xgb__max_depth': 15, 'xgb__gamma': 0, 'xgb__eta': 0.1}\n",
      "train time =  05:16:51\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create the grid\n",
    "xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 5)] # Number of trees to be used\n",
    "xgb_max_depth = [int(x) for x in np.linspace(2, 20, 5)] # Maximum number of levels in tree\n",
    "xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 5)] # Minimum number of instaces needed in each node\n",
    "xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist'] # Tree construction algorithm used in XGBoost\n",
    "xgb_eta = [x for x in np.linspace(0.1, 0.6, 3)] # Learning rate\n",
    "xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 3)] # Minimum loss reduction required to make further partition\n",
    "xgb_objective = ['reg:squarederror', 'reg:squaredlogerror'] # Learning objective used\n",
    "xgb_grid = {'xgb__n_estimators': xgb_n_estimators,\n",
    "            'xgb__max_depth': xgb_max_depth,\n",
    "            'xgb__min_child_weight': xgb_min_child_weight,\n",
    "            'xgb__tree_method': xgb_tree_method,\n",
    "            'xgb__eta': xgb_eta,\n",
    "            'xgb__gamma': xgb_gamma,\n",
    "            'xgb__objective': xgb_objective}\n",
    "\n",
    "#xgb = XGBRegressor()\n",
    "# Create the random search Random Forest\n",
    "pipe  = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                        ('xgb', XGBRegressor())])\n",
    "xgb_random = RandomizedSearchCV(pipe, param_distributions = xgb_grid, \n",
    "                                n_iter = 100, cv = 3, verbose = 2, \n",
    "                                random_state = 42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "y_pred = xgb_random.predict(X_test)\n",
    "\n",
    "xgb_mae =  mean_absolute_error(y_test, y_pred)\n",
    "xgb_mse =  mean_squared_error(y_test, y_pred)\n",
    "xgb_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"mae = {:.2f}\".format(xgb_mae))\n",
    "print(\"mse = {:.2f}\".format(xgb_mse))\n",
    "print(\"r2_score = {:.3f}\".format(xgb_r2_score))\n",
    "print(\"best params =\", xgb_random.best_params_)\n",
    "print(\"train time = \", time.strftime('%H:%M:%S', time.gmtime(time.time()-time_start)))\n",
    "print(\"--------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_comparison(models, test_features, test_labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for model in models:\n",
    "        predictions = model.predict(test_features)\n",
    "        mae = mean_absolute_error(test_labels, predictions)\n",
    "        mse = mean_squared_error(test_labels, predictions)\n",
    "        r2 = r2_score(test_labels, predictions)\n",
    "        errors = abs(predictions - test_labels)\n",
    "        mape = 100 * np.mean(errors / test_labels)\n",
    "        accuracy = 100 - mape\n",
    "        scores[str(model)] = [mae, mse, r2, accuracy]\n",
    "    scores.index = ['Mean Absolute Error', 'Mean Squared Error', 'R^2', 'Accuracy']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                        ('linear', LinearRegression())])\n",
    "\n",
    "xgb_pipe =  Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                        ('xgb', XGBRegressor(tree_method = 'approx',\n",
    "                         objective = 'reg:squarederror',\n",
    "                         n_estimators = 650,\n",
    "                         min_child_weight = 3,\n",
    "                         max_depth = 15,\n",
    "                         gamma = 0,\n",
    "                         eta = 0.1,\n",
    "                         random_state = 42))])\n",
    "\n",
    "rf_pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('rf', RandomForestRegressor(criterion='mse', n_estimators=100))])\n",
    "\n",
    "gb_pipe = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                          ('gb', GradientBoostingRegressor(criterion='mse', n_estimators=100))])\n",
    "\n",
    "linear_final=linear_pipe.fit(X_train, y_train)\n",
    "xgb_final=xgb_pipe.fit(X_train, y_train)\n",
    "rf_final=rf_pipe.fit(X_train, y_train)\n",
    "gb_final=gb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Extreme Gradient Boosting</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>4.345218e+04</td>\n",
       "      <td>1.098626e+04</td>\n",
       "      <td>1.135305e+04</td>\n",
       "      <td>1.627313e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>3.086799e+09</td>\n",
       "      <td>2.913981e+08</td>\n",
       "      <td>2.622274e+08</td>\n",
       "      <td>4.552113e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2</th>\n",
       "      <td>5.295008e-01</td>\n",
       "      <td>9.555842e-01</td>\n",
       "      <td>9.600305e-01</td>\n",
       "      <td>9.306153e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>7.407875e+01</td>\n",
       "      <td>9.401217e+01</td>\n",
       "      <td>9.370295e+01</td>\n",
       "      <td>9.054586e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Linear Regression  Extreme Gradient Boosting  \\\n",
       "Mean Absolute Error       4.345218e+04               1.098626e+04   \n",
       "Mean Squared Error        3.086799e+09               2.913981e+08   \n",
       "R^2                       5.295008e-01               9.555842e-01   \n",
       "Accuracy                  7.407875e+01               9.401217e+01   \n",
       "\n",
       "                     Random Forest  Gradient Boosting  \n",
       "Mean Absolute Error   1.135305e+04       1.627313e+04  \n",
       "Mean Squared Error    2.622274e+08       4.552113e+08  \n",
       "R^2                   9.600305e-01       9.306153e-01  \n",
       "Accuracy              9.370295e+01       9.054586e+01  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the comparison function with the three final models\n",
    "reg_scores = regressor_comparison([linear_final, xgb_final, rf_final, gb_final], X_test, y_test)\n",
    "reg_scores.columns  = ['Linear Regression', 'Extreme Gradient Boosting', 'Random Forest', 'Gradient Boosting']\n",
    "reg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
